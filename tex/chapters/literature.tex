%!TEX root = ../main.tex

\chapter{Literature Review}\label{cha:literature_review}

The Prisoner's Dilemma is a very popular model in game theory and there have been many papers written about the subject.
The start of this chapter will give a brief overview of the literature and particularly relevant work will be highlighted.
This is followed by an outline of how Axelrod's work is currently being reproduced by an open-source community.
Finally, an introduction to fingerprinting and some necessary definitions and theorems are given at the end of the chapter.


\section{Background}\label{sec:axelrodoriginal}

The political scientist Robert Axelrod held the first IPD tournament in 1980 \cite{Axelrod1980a}.
Many well-known game theorists were invited to submit strategies that would compete against each other in a round robin style format.
All strategies also competed against a random strategy (that would randomly choose between `C' and `D') and a copy of themselves.
All strategies knew that the length of each game was 200 moves, and the whole tournamtent was repeated 5 times for reliability.
Out of the 13 strategies that were entered, TitForTat was announced as the winner and was submitted by Professor Anatol Rapoport from the Department of Psychology of the University of Toronto.

TitForTat is a very simple strategy that begins by playing `C' and then plays the same move as it opponent did on the previous turn.
As explained in \cite{Axelrod1980b}, TitForTat won because of three defining characteristics:

\begin{itemize}
    \item `Niceness' - A strategy is said to be nice if it is not the first to defect.
    \item `Provocability' - Immediately after an opponent defects, the strategy should defect in retaliation.
    \item `Forgiveness' - The strategy is willing to continue with mutual cooperation even after some defections.
\end{itemize}

Axelrod's second tournament \cite{Axelrod1980b} saw a dramatic increase in terms of size, with 62 strategies ebing entered from 6 different countries.
The contestants ranged from a 10-year-old computer hobbyist to professors of computer science, economics, psychology, mathematics, sociology, political science and evolutionary biology.
The countries represented were the United States, Canada, Great Britain, Norway, Switzerland, and New Zealand.
Despite the fact that all contestants had full knowledge of the previous tournament, TitForTat was the overall winner once again.
One large difference in the mechanics of the first and second tournament was that the second tournament did not specify how many moves a game would last.
Instead, the game ended probabilistically with a 0.00346 chance of finishing on any given move.
This parameter was chosen so that the median length of a game would be 200 moves (in line with the first tournament).

\begin{table}[htbp]
\centering
\begin{tabular}{c c c c}
Year & Reference & Number of Strategies & Type\\
\hline
1979 & \cite{Axelrod1980a} & 13 & Standard\\
1979 & \cite{Axelrod1980b} & 64 & Standard\\
1984 & & 64 & Evolutionary\\
1991 & & 13 & Noisy\\
2005 & & 223 & Varied\\
2012 & & 13 & Standard\\
\hline
\end{tabular}
\label{tab:tournament_refs}
\caption{An overview of published tournaments}
\end{table}

\section{Axelrod-Python Library}

The Axelrod-Python library \cite{axelrodproject} is an open source Python package for creating reproducable research into the Prisoner's Dilemma.
The original aim was to recreate Axelrod's tournaments as described in section \ref{sec:axelrodoriginal} and verify their results.
For many of the tournaments that have been described the orignal source code is not available, and in the few cases where access was available there were no tests and minimal documentation.

The Axelrod-Python library is equipped with an extensive tests suite and all code is comprehensively documented.
The documentation can be found at \url{http://axelrod.readthedocs.io/en/latest/} along with several tutorials designed to help introduce researchers to the library.
In total the library now consists of 147 strategies (at the time of writing) including classical ones from the literature and and some exciting original contributions.
It is interesting that the original winner, TitForTat, is currently ranked 49th overall.
The library also has the capability to run ecological simulations or construct tournaments on alternative topologies (not just the original round robin format).

An example implementation of a strategy and a demonstration of using the library will now be given, followed by examples of some of the many plots the library can produce.
The source code for TitForTat is shown in Listing \ref{lst:TFT}.

\begin{listing}[htbp!]
\begin{SourceCode}
class TitForTat(Player):
    """
    A player starts by cooperating and then mimics the previous action of the
    opponent.

    Note that the code for this strategy is written in a fairly verbose
    way. This is done so that it can serve as an example strategy for
    those who might be new to Python.

    Names:

    - Rapoport's strategy: [Axelrod1980]_
    - TitForTat: [Axelrod1980]_
    """

    # These are various properties for the strategy
    name = 'Tit For Tat'
    classifier = {
        'memory_depth': 1,  # Four-Vector = (1.,0.,1.,0.)
        'stochastic': False,
        'makes_use_of': set(),
        'long_run_time': False,
        'inspects_source': False,
        'manipulates_source': False,
        'manipulates_state': False
    }

    def strategy(self, opponent):
        """This is the actual strategy"""
        # First move
        if not self.history:
            return C
        # React to the opponent's last move
        if opponent.history[-1] == D:
            return D
        return C
\end{SourceCode}
\caption{Source code for TitForTat}
\label{lst:TFT}
\end{listing}

Strategies are implemented as classes with a \mintinline{python}{strategy} method.
The strategy method contains the logic that defines how the strategy will behave as can be seen in Listing \ref{lst:TFT} lines 28 - 36.
If the player does not have a history then it must be the first move and it chooses to play `C'.
On all subsequent moves the player checks whether the opponent played `D' on it's previous move.
If that statement is true the player also plays `D', otherwise it will play `C'.

In Listings \ref{lst:tournament} an example of how to produce a simple tournament is shown.
Lines 7 - 10 create two plots.
The first is a ranked violion plot of the mean payoff for each player and the second is a matrix plot of pair wise payoffs for each player.
These plots can be seen

\begin{listing}[htbp!]
\begin{ExampleCode}
>>> import axelrod as axl
>>> axl.seed(0)  # Set a seed
>>> players = [s() for s in axl.strategies]  # Create players
>>> tournament = axl.Tournament(players)  # Create a tournament
>>> results = tournament.play()  # Play the tournament
>>> plot = axl.Plot(results)
>>> p = plot.boxplot()
>>> p.show()
>>> q = plot.payoff()
>>> q.show()
\end{ExampleCode}
\caption{Example code to produce a simple tournament}
\label{lst:tournament}
\end{listing}

\begin{figure}
%TODO
\begin{center}
\caption{Ranked violin plot of th mean payoff for each player}
\label{fig:violinplot}
\end{center}

\begin{center}
\caption{Matrix plot of pair wise payoffs for each player}
\label{fig:matrixplot}
\end{center}
\end{figure}

is often used to model systems in biology ~\cite{Sigmund1999}, sociology ~\cite{Franken2005},
psychology ~\cite{Ishibuchi2005}, and economics ~\cite{Chong2005}.


\section{Fingerprinting}\label{sec:fingerprinting}
It is easy to produce large numbers of strategies, however their analysis can be time consuming.
Even the simple question `Are these two strategies the same?' does not always have an obvious answer.
This is especially true when considering source code, as two identical strategies can be coded in very ways.

A method for comparing strategies is first given in ~\cite{Ashlock2004}.
Ashlock outlines several definitions, theorems and proofs concerning the construction of a fingerprint which are then followed by some examples.
The examples presented are of low quality and the only probe strategy (see section/definition etc) used is TitForTat.
%TODO - ref definition of probe?

Ashlock then extends his fingerprinting work further in ~\cite{Ashlock2008}.
Far more examples are presented, and many different fingerprint functions are listed.
A large number of the analytical fingerprint functions use a probe that is not TitForTat.
Fingerprinting is then used to to assess how three evolutionary algorithms produce different populations.
The evolutionary methods involved are finite-state machines, lookup tables and feedforward neural nets.


\begin{definition}\label{def:joss-ann}
If $A$ is a strategy for playing the iterated prisoner's dilemma, then the \textbf{Joss-Anne of A}, $\JA(A, x, y)$ is a transformation of that strategy.
Instead of the original behaviour, it makes move `C' with probablility $x$, move `D' with probability $y$, and otherwise uses the response appropriate to strategy $A$ (if $x+y < 1$).
\end{definition}

The notation $\JA$ comes from the initials of the names Joss and Anne.
Joss was a strategy submitted to one of Axelrodâ€™s original tournaments and it would occasionally defect without provocation in the hopes of a slight improvement in score.
Anne is the first name of A. Stanley who suggested the addition of random cooperation (refs from ashlock paper) instead of random defection ~\cite{Ashlock2008}. %TODO - find refs from ashlock
When $x + y = 1$, the original strategy is not used, and the resulting behavior is a random strategy with probabilities $(x, y)$.
In more general terms, a $\JA$ strategy is an alteration of a strategy $A$ that causes the strategy to be played with random noise inserted into the responses.

\begin{definition}\label{def:fingerprint}
A \textbf{Fingerprint} $F_A(S, x, y)$ with $0 \leq x, y \leq 1$, $x+y \leq 1$ for strategy $S$ and probe $A$, is the function that returns the expected score of strategy $S$ against $\JA(A, x, y)$ for each possible $(x, y)$.
\end{definition}


\begin{definition}\label{def:double-fingerprint}
The \textbf{Double Fingerprint} $F_{AB}(S, x, y)$ with $0 \leq x, y \leq 1$ returns the expected score of strategy $S$ against $\JA(A, x, y)$ if $x+y \leq 1$, and $\JA(B, 1-y, 1-x)$ if $x+y \geq 1$.
\end{definition}


\begin{definition}\label{def:dual}
Strategy $A'$ is said to be the \textbf{Dual} of strategy $A$ if $A$ and $A'$ can be written as finite-state machines that are identical except that their responses are reversed.
\end{definition}

An alternative wording is that, given a history for an opponent, the responses of the original strategy and the dual would be opposite.
It is important to note that this is different to taking a strategy and flipping it's responses.
The dual relies on knowledge of the underlying state of the original strategy, whereas the flip does not.
This is shown in Table \ref{tab:strat-dual-flip}.

%TODO - Define Pavlov
%TODO - Flip
\begin{table}[htbp]
\centering
\begin{tabular}{l l l l}
\toprule
Opponent & Pavlov & Dual & Flip \\
\midrule
C & C & D & D \\
D & C & D & C \\
D & D & C & C \\
C & C & D & C \\
C & C & D & D \\
D & C & D & C \\
C & D & C & C \\
D & D & C & D \\
  & C & D & D \\
\bottomrule
\end{tabular}
\caption{The different responses of Pavlov, Pavlov's Dual and Flipped Pavlov}
\label{tab:strat-dual-flip}
\end{table}

The subtle difference between Dual and Flip can be highlighted further by inspecting each row individualy.

\underline{Row 1} - Pavlov always plays `C' on the first go.
Flip will change this to `D'.
Dual knows that Pavlov always plays `C' and so swaps to `D'.

\underline{Row 2} - In the previous round for Pavlov the strategies played $(C, C)$, and so Pavlov plays `C' again.
For Flip, the preceding interaction was $(D, C)$, in this instance Pavlov would play `D' again, so this gets flipped to `C'.
The previous turn for Dual was $(D, C)$ so it infers that Pavlov had $(C, C)$.
It knows that Pavlov would play `C' and so plays `D'.

\underline{Row 3} - In the previous round for Pavlov the strategies played $(C, D)$, and so Pavlov would change to play `D'.
For Flip, the preceding interaction was $(C, D)$, in this instance Pavlov would change to `D', so this gets flipped to play `C' again.
The previous turn for Dual was $(D, D)$ so it infers that Pavlov had $(C, D)$.
It knows that Pavlov would play `D' in this instance and so plays `C'.



\begin{theorem}\label{thm:fingerprint-unit-square}
If $A$ and $A'$ are dual strategies, then $F_{AA'}(S, x, y)$ is identical to the function $F_A(S, x, y)$ extended over the unit square.
\end{theorem}

A proof for this theorem will now be given which was first presented in \cite{Ashlock2004}:
\begin{proof}\label{prf:fingerprint-unit-square}
The Markov chain for the dual strategy $A'$ will have the same transitions as the Morkov chain for the strategy $A$.
However, each entry for $x$ corresponds to the probability that the strategy $\JA(A, x, y)$ will randomly choose `C' when it would not normally do so.
For strategy $A'$, this will occur whenever $\JA(A', x, y)$ does not randomly respond `D', which has probability $1 - y$.

Similarly, each $y$ corresponds to the probability that the strategy $\JA(A, x, y)$ will randomly choose `D' when it would usually respond `C'.
For strategy $A'$, this will occur whenever $\JA(A', x, y)$ does not randomly respond `C', which has probability $1 - x$.

Thus the Markov chain for $\JA(A', x, y)$ is the Markov chain for $\JA(A, x, y)$ with the mapping $(x, y) \rightarrow (1-y, 1-x)$.
Therefore $F_{AA'}(S, x, y)$ extends to the remainder of the unit square the function given by $F_A(S, x, y)$. $\blacksquare$
\end{proof}

Theorem \ref{thm:fingerprint-unit-square} allows the fingerprint function to naturally extend over the unit square.
Figure \ref{fig:DualProbe} shows that in the \textcolor{sol-violet}{bottom left} region of the plot, the strategy plays against $\JA(A, x, y)$ and in the \textcolor{sol-cyan}{top right} region it plays against $\JA(A', 1-y, 1-x)$.

\begin{figure}[!hbtp]
    \begin{center}
        \includestandalone{../img/Dual}
        \caption{Whether the Strategy is probed by the Dual or not}\label{fig:DualProbe}
    \end{center}
\end{figure}




\solarizedPalette


