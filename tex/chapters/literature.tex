%!TEX root = ../main.tex

\chapter{Literature Review}\label{cha:literature_review}

The Prisoner's Dilemma is a very popular model in game theory and there have been many papers written about the subject.
The game has been applied to many different research areas is often used to model systems in biology \cite{Sigmund1999}, sociology \cite{Franken2005}, psychology \cite{Ishibuchi2005}, and economics \cite{Chong2005}.
The start of this chapter will give a brief overview of the literature and particularly relevant work will be highlighted.
This is followed by an outline of how Axelrod's work is currently being reproduced by an open-source community.
Finally, an introduction to fingerprinting and some necessary definitions and theorems are given at the end of the chapter.


\section{Background}\label{sec:axelrodoriginal}

The political scientist Robert Axelrod held the first IPD tournament in 1980 \cite{Axelrod1980a}.
Many well-known game theorists were invited to submit strategies that would compete against each other in a round robin style format.
All strategies also competed against a random strategy (that would randomly choose between `C' and `D') and a copy of themselves.
All strategies knew that the length of each game was 200 moves, and the whole tournament was repeated 5 times for reliability.
Out of the 13 strategies that were entered, TitForTat was announced as the winner and was submitted by Professor Anatol Rapoport from the Department of Psychology of the University of Toronto.

TitForTat is a very simple strategy (see Section \ref{ssec:stra_titfortat}) and as explained in \cite{Axelrod1980b}, it won because of three defining characteristics:

\begin{itemize}
    \item `Niceness' - A strategy is said to be nice if it is not the first to defect.
    \item `Provocability' - Immediately after an opponent defects, the strategy should defect in retaliation.
    \item `Forgiveness' - The strategy is willing to continue with mutual cooperation even after some defections.
\end{itemize}

Axelrod's second tournament \cite{Axelrod1980b} saw a dramatic increase in terms of size, with 62 strategies being entered from 6 different countries.
The contestants ranged from a 10-year-old computer hobbyist to professors of computer science, economics, psychology, mathematics, sociology, political science and evolutionary biology.
The countries represented were the United States, Canada, Great Britain, Norway, Switzerland, and New Zealand.
Despite the fact that all contestants had full knowledge of the previous tournament, TitForTat was the overall winner once again.
One large difference in the mechanics of the first and second tournament was that the second tournament did not specify how many moves a game would last.
Instead, the game ended probabilistically with a 0.00346 chance of finishing on any given move.
This parameter was chosen so that the median length of a game would be 200 moves (in line with the first tournament).

\begin{table}[htbp]
\centering
\begin{tabular}{c c c c}
\toprule
Year & Reference & Number of Strategies & Type\\
\midrule
1979 & \cite{Axelrod1980a} & 13 & Standard\\
1979 & \cite{Axelrod1980b} & 64 & Standard\\
1984 & \cite{Axelrod1981} & 64 & Evolutionary\\
1991 & \cite{Bendor1991} & 13 & Noisy\\
2005 & \cite{Chong2004} & 223 & Varied\\
2012 & \cite{Stewart2012} & 13 & Standard\\
\bottomrule
\end{tabular}
\label{tab:tournament_refs}
\caption{An overview of published tournaments}
\end{table}

Axelrod continued to extend his work by considering an evolutionary version of the tournament \cite{Axelrod1981, Axelrod1984}.
In this case, the proportion of the population playing a certain strategy depends on how the strategy performed on the previous round.
A strategy is evolutionarily stable if a population of individuals using that strategy cannot be invaded by a rare mutant adopting a different strategy \cite{Axelrod1981}.

In \cite{Nowak1992, Nowak1993, Nowak1994}, Nowak extends this further by studying Spatial Games.
In his variation, the game is played on a 2 dimensional square lattice where the payoff for an individual is the sum over all interactions with its 8 nearest neighbours (see Figure \ref{fig:nowak_spatial}) and itself.
In the next generation, an individual cell is occupied with the strategy that received the highest payoff among all 8 nearest neighbours and itself.

\begin{figure}[hbtp!]
\centering
\begin{tikzpicture}
\fill[gray] (1,1) rectangle (4,4);
\fill[sol-magenta] (2,2) rectangle (3,3);
\draw[step=1cm] (-0.9,-0.9) grid (5.9,5.9);
\end{tikzpicture}
\caption{The topology of Nowak's spatial variation}
\label{fig:nowak_spatial}
\end{figure}

To simplify things, Nowak limited each cell to be either Cooperator or Defector.
Thus the game is completely deterministic and the outcome depends on the initial configuration and the payoff matrix.
One particularly interesting result is that if a single Defector invades a world of Cooperators, long (but finite) sequences of patterns emerge.
Due to the symmetry of the game rules, all the patterns are highly symmetric and have the appearance of kaleidoscopes.

The primary purpose of \cite{Bendor1991} was to discover the effect of noise on TitForTat's performance in IPD.
As had been previously claimed its performance was significantly reduced.
The authors of \cite{Bendor1991} suggest that this is due to the provocability mentioned earlier, which in the presence of noise, can causes it to fall into unintended vendettas with other nice, but provocable strategies.
Strategies that outperformed TitForTat were far more forgiving, which enabled them to get back to mutual cooperation much faster after an accidental defection.



\section{Strategies of Particular Interest}\label{sec:individual_strategies}
Throughout this report many different strategies will be discussed and used in small examples.
This section will provide a description of some of these strategies in order to aid the reader, as a strategy's name is not always particularly descriptive.

\subsection{TitForTat}\label{ssec:stra_titfortat}
TitForTat is the most well known strategy for playing Prisoner's Dilemma due to it winning both of Axelrod's first two tournaments.
It starts with a cooperative move and proceeds to play the same as the opponent did on the previous move \cite{Axelrod1980b, Heap2003}.

\subsection{Pavlov}\label{ssec:strat_pavlov}
In \cite{Nowak1993}, the strategy Pavlov is introduced (sometimes referred to as Win-Stay Lose-Shift).
Pavlov plays by repeating its previous move if it was successful (received payoff $T$ or $R$), and swapping the move if it was unsuccessful (received payoff $P$ or $S$).
The paper explains how this allows it take advantage of strategies that cooperate unconditionally and can also correct occasional mistakes.

\subsection{Gradual}\label{ssec:strat_gradual}
The strategy Gradual is present in \cite{Beaufils1997}.
It begins the game by cooperating, then after the first defection of the other player, it defects one time and cooperates twice.
After the second defection of the opponent, it defects two times and cooperates twice.
After the $n^{th}$ defection it reacts with $n$ consecutive defections and then two cooperations.
In \cite{Beaufils1997} it is claimed that Gradual outperforms TitForTat and this has been confirmed by work done through the Axelrod-Python library \cite{Knight2016}.

\subsection{Random}\label{ssec:strat_random}
Random plays exactly as expected, by choosing randomly between whether to cooperate or defect.
The probabilities of choosing cooperate or defect are not necessarily even, instead they could rely on some distribution.
We will denote the strategy that chooses to cooperate with probability $p$ as Random($p$).
For example, the strategy that randomly chooses to cooperate $20\%$ of the time and defect $80\%$ of the time would be Random($0.2$).

\subsection{Cooperator/Defector}\label{ssec:strat_coop_defect}
Cooperator and Defector are very simple.
Cooperator will choose to cooperate at every turn, and similarly Defector will choose to defect every turn.

\subsection{Cycler}\label{ssec:strat_cycler}
The strategy Cycler($s$) will repeat a given sequence of moves $s$.
For example Cycler(CD) would play CDCDCD... and Cycler(CDDDC) would play CDDDCCDDDCCDDDC...

\subsection{Evolved Looker-Up}\label{ssec:strat_evolved_lu}
The winning strategy in the version of Axelrod-Python used throughout this paper is Evolved Looker-Up.
The author, Martin Jones, has produced a thorough explanation of how the strategy was written in \cite{MoJones}, and a brief outline will be given here.
Quite simply, the strategy uses a lookup table to determine the action it should take.
A lookup table is similar to a dictionary when programming, where the keys could be the opponents previous moves and the values the next action the strategy should take.
The length of the key could be extended to include the opponents two previous moves (or more).
It is clear that for a key length $l$, there are $n = 2^l$ keys.
For each key the next action could be Cooperate or Defect, and so there are a total of $2^n$ possible lookup tables.
Evolved Looker-up uses as its keys: the opponents first two moves, the opponents previous two moves, and the strategies own previous two moves.
So we have $n = 2^6 = 64$ keys, and therefore $2^{64} \simeq 10^{18}$ possible lookup tables.

An evolutionary algorithm is then used to find the best possible table.
The operates by initially creating a population of many different lookup tables.
Then a new lookup table is created by combining two pre existing ones together (similar to how DNA is joined in reproduction).
There is a probability (normally low) of some of the new lookup table mutating.
Next, several more random lookup tables are produced.
Finally, all lookup tables are scored and poor performers are discarded.
Then the whole process is repeated with the new generation of lookup tables.

Evolved Looker-Up was produced after 200 generations, and the final lookup table can be found in the Axelrod-Python source code.
Alternatively, the code used to produce the lookup table is given in \cite{axelrod-evolver}.

\section{Finite State Machines and Automaton}

\section{Axelrod-Python Library}

The Axelrod-Python library \cite{axelrodproject} is an open source Python package for creating reproducible research into the Prisoner's Dilemma.
The original aim was to recreate Axelrod's tournaments as described in section \ref{sec:axelrodoriginal} and verify their results.
As the library has grown, so has the overall aim.
The goal now, is "to provide a resource, with facilities for the design of new strategies and interactions between them, as well as conducting tournaments and ecological simulations for populations of strategies" \cite{Knight2016}.
For many of the tournaments that have been described the original source code is not available, and in the few cases where access was available there were no tests and minimal documentation.

In listing \ref{lst:tournament} an example of how to produce a simple tournament is shown.
Lines 7 - 10 create two plots.
The first is a ranked violin plot of the mean payoff for each player and the second is a matrix plot of pair wise payoffs for each player.
These plots can be seen in figures \ref{fig:violinplot} and \ref{fig:matrixplot}.

\begin{listing}[htbp!]
\begin{ExampleCode}
>>> import axelrod as axl
>>> axl.seed(0)  # Set a seed
>>> players = [s() for s in axl.strategies]  # Create players
>>> tournament = axl.Tournament(players)  # Create a tournament
>>> results = tournament.play()  # Play the tournament
>>> plot = axl.Plot(results)
>>> p = plot.boxplot()
>>> p.show()
>>> q = plot.payoff()
>>> q.show()
\end{ExampleCode}
\caption{Example code to produce a simple tournament}
\label{lst:tournament}
\end{listing}

\begin{figure}
%TODO
\begin{center}
\caption{Ranked violin plot of the mean payoff for each player}
\label{fig:violinplot}
\end{center}

\begin{center}
\caption{Matrix plot of pair wise payoffs for each player}
\label{fig:matrixplot}
\end{center}
\end{figure}


\section{Fingerprinting}\label{sec:fingerprinting}
It is easy to write a genetic algorithm to produce large numbers of strategies, however their analysis can be time consuming.
Even the simple question `Are these two strategies the same?' does not always have an obvious answer.
This is especially true when considering source code, as two identical strategies can be coded in different ways.
For example, differentiating between Random($0.5$) and Cycler(CD) (see Section \ref{sec:individual_strategies}) isn't trivial unless you have access to their source code.
The results of a game they play isn't necessarily enough.

A method for comparing strategies is first given in \cite{Ashlock2004}.
Ashlock outlines several definitions, theorems and proofs concerning the construction of a fingerprint.
These are then followed by some examples, however they are of low quality and the only probe (see section/definition etc) used is TitForTat.
%TODO - ref definition of probe?

Ashlock then extends his fingerprinting work further in \cite{Ashlock2008}.
More examples are presented, and many different fingerprint functions are listed.
Also, a large number of the analytical fingerprint functions use a probe that is not TitForTat.
Fingerprinting is then used to to assess how three evolutionary algorithms produce different populations.
The evolutionary methods involved are finite-state machines, lookup tables and feed forward neural nets.

