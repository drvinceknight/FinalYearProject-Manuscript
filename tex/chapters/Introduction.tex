%!TEX root = ../main.tex

\chapter{Introduction}\label{cha:introduction}

The Prisoner's Dilemma (PD) is a classical model in Game Theory.
It is a simple two player game where the agents must make a binary decision without communicating.
This is often presented as two suspects who have been arrested and are being interrogated separately.
They have the option of whether to cooperate with each other or defect and each player receives an indivual payoff that depends on the actions that have been taken.

Now, consider the situation that both prisoners return to their cells each night, to be presented with the same choice the next day.
Furthermore, allow this process to continue repeatadely. 
This is called the Iterated Prisoner's Dilemma (IPD) and has been an object of interest ever sincethe 1950's but became more popular after Robert Axelrod's large amount of work in the 1980's.

Several computer based IPD tournament have been held over the years, but the first was held by Axelrod in 1980 (use our paper for refs).
Subsequently, two anniversary tournaments were held in 2004 and finally there was the Stewart and Plotkin 2012 tournament.
The original source code of these is only available for Axelrod's second tournament (in FORTRAN) and it is not well documented, tested or easily re-useable.

Recently, a group of scientists have been working to improve this situation by producing an open source version of Axelrod's original tournament ~\cite{Knight2016}.
Referred to as the Axelrod-Python library, it aims to provide a resource for the design of new strategies and interactions between them, as well as conducting tournaments and ecologi-cal simulations for populations of strategies.
At the time of writing, the library has 139 strategies implemented with the capability to run evolutionary tournaments and tournaments on different topologies.

\section{Prisoner's Dilemma}
The first formal definition of PD was presented by Albert W. Tucker during a seminar at Stanford University ~\cite{Gass2005}.
However, the idea was first formulated by the Merrils ~\cite{Flood1958} in 1950 whilst working for the RAND cooperation.

A desription of the PD - Two players simultaneously decide whether to Cooperate $(C)$ or Defect $(D)$, without exchanging information.
They receive payoffs as follows:

\begin{itemize}
\item They both choose $C$ (mutual cooperation) and receive a payoff $R$ (Reward)
\item They both choose $D$ (mutual defection) and receive a payoff $P$ (Punish)
\item One player chooses $C$ and the other chooses $D$. The cooperator receives a payoff $S$ (Sucker) and the defector receives a payoff $T$ (Temptation).
\end{itemize}

Figure \ref{eq:payoff_matrix_symb} shows the payoff matrix.

\begin{equation}\label{eq:payoff_matrix_symb}
% 
P = \bordermatrix{~ & C & D \cr
                  C & (R, R) & (T, S) \cr
                  D & (S, T) & (P, P) \cr}
% 
\end{equation}

There are also two assumptions that need to be stated.
Firstly, both players are rational.
Secondly, there is no communication between them.
It is then easy to see that regardless of the choice of one player, the other will always obtain a higher payoff by defecting instead of cooperating.
Therefore we have a pure Nash Equilibrium where both players defect, despite the fact that both players would do better if they were to cooperate with each other.
Additionaly, to ensure this behaviour occurs, the payoffs must satisfy the following inequalities:

\begin{equation}\label{eq:intuitive}
S < D < C < T
\end{equation}

and

\begin{equation}\label{eq:ensure_coop}
(S + T) < 2 C
\end{equation}

Equation \ref{eq:intuitive} merely fixes the payoffs in their intuitive order.
Equation \ref{eq:ensure_coop} ensures that alternating between cooperating and defecting (players take it in turns to stab each other in the back) performs no better than mutual cooperation.
These inequalities allow for many different payoff matrices to be formulated, but values of $(R, S, T, P) = (3, 0, 5, 1)$ are commonly used in literature (find references).
We can now formulate the new payoff matrix, as shown in Figure \ref{eq:payoff_matrix}
A more detailed explanation of the Prisoner's Dilemma is given in ~\cite{Gotts2003}.

\begin{equation}\label{eq:payoff_matrix}
% 
P = \bordermatrix{~ & C & D \cr
                  C & (3, 3) & (5, 0) \cr
                  D & (0, 5) & (1, 1) \cr}
% 
\end{equation}

\section{Problem Description}

As previously mentioned, the Axelrod-Python library contains 139 strategies, significantly more than the 13 and 64 strategies submitted to Axelrod's first and second tournaments.
This now raises the issue of duplication, and subsequently, how to tell the difference between strategies.
Currently the most popular method is Fingerprinting which produces a visual representation of a strategy, an example is shown in Figure.

The issue with this method is that it relies on knowledge of the underlying markov chain of the strategy which cannot be easily constructed from the source code.

More needed once we know what's actually gonna happen.


\section{Structure}
This report is organized into several chapters. Continuing from this introduction:

\begin{itemize}
    \item Chapter \ref{cha:awesome_theorems_and_stuff}
    
    \item Chapter \ref{cha:conclusion}
\end{itemize}










\begin{tabular}{ l | l l l l l }
& 0.0 & 0.2 & 0.4 & 0.6 & 0.8 \\ 
\hline 
0.0 & (C, C): (1.00, nan) & (C, C): (0.04, 0.00) & (C, C): (0.02, 0.00) & (C, C): (0.01, 0.00) & (C, C): (0.00, 0.00) \\ 
 & (C, D): (0.00, nan) & (C, D): (0.35, 0.36) & (C, D): (0.39, 0.38) & (C, D): (0.42, 0.42) & (C, D): (0.46, 0.45) \\ 
 & (D, C): (0.00, nan) & (D, C): (0.27, 0.29) & (D, C): (0.22, 0.23) & (D, C): (0.16, 0.17) & (D, C): (0.09, 0.09) \\ 
 & (D, D): (0.00, nan) & (D, D): (0.34, 0.36) & (D, D): (0.38, 0.38) & (D, D): (0.41, 0.42) & (D, D): (0.45, 0.45) \\ 
\\
0.2 & (C, C): (1.00, 1.00) & (C, C): (0.27, 0.25) & (C, C): (0.17, 0.15) & (C, C): (0.13, 0.12) & (C, C): (0.10, 0.10) \\ 
 & (C, D): (0.00, 0.00) & (C, D): (0.24, 0.25) & (C, D): (0.31, 0.31) & (C, D): (0.35, 0.35) & (C, D): (0.40, 0.40) \\ 
 & (D, C): (0.00, 0.00) & (D, C): (0.24, 0.25) & (D, C): (0.22, 0.23) & (D, C): (0.17, 0.18) & (D, C): (0.10, 0.10) \\ 
 & (D, D): (0.00, 0.00) & (D, D): (0.24, 0.25) & (D, D): (0.30, 0.31) & (D, D): (0.35, 0.35) & (D, D): (0.39, 0.40) \\ 
\\ 
0.4 & (C, C): (1.00, 1.00) & (C, C): (0.40, 0.38) & (C, C): (0.22, 0.25) & (C, C): (0.19, 0.20) & (C, C): (0.15, 0.18) \\ 
 & (C, D): (0.00, 0.00) & (C, D): (0.18, 0.19) & (C, D): (0.25, 0.25) & (C, D): (0.31, 0.30) & (C, D): (0.34, 0.35) \\ 
 & (D, C): (0.00, 0.00) & (D, C): (0.24, 0.25) & (D, C): (0.27, 0.25) & (D, C): (0.20, 0.20) & (D, C): (0.17, 0.12) \\ 
 & (D, D): (0.00, 0.00) & (D, D): (0.18, 0.19) & (D, D): (0.25, 0.25) & (D, D): (0.30, 0.30) & (D, D): (0.33, 0.35) \\ 
\\ 
0.6 & (C, C): (1.00, 1.00) & (C, C): (0.45, 0.43) & (C, C): (0.30, 0.30) & (C, C): (0.25, 0.25) & (C, C): (0.21, 0.23) \\ 
 & (C, D): (0.00, 0.00) & (C, D): (0.13, 0.14) & (C, D): (0.20, 0.20) & (C, D): (0.25, 0.25) & (C, D): (0.29, 0.31) \\ 
 & (D, C): (0.00, 0.00) & (D, C): (0.30, 0.29) & (D, C): (0.31, 0.30) & (D, C): (0.26, 0.25) & (D, C): (0.22, 0.15) \\ 
 & (D, D): (0.00, 0.00) & (D, D): (0.13, 0.14) & (D, D): (0.19, 0.20) & (D, D): (0.24, 0.25) & (D, D): (0.28, 0.31) \\ 
\\
0.8 & (C, C): (1.00, 1.00) & (C, C): (0.42, 0.40) & (C, C): (0.35, 0.29) & (C, C): (0.30, 0.25) & (C, C): (0.25, 0.25) \\ 
 & (C, D): (0.00, 0.00) & (C, D): (0.09, 0.10) & (C, D): (0.16, 0.14) & (C, D): (0.21, 0.19) & (C, D): (0.25, 0.25) \\ 
 & (D, C): (0.00, 0.00) & (D, C): (0.40, 0.40) & (D, C): (0.33, 0.43) & (D, C): (0.29, 0.38) & (D, C): (0.26, 0.25) \\ 
 & (D, D): (0.00, 0.00) & (D, D): (0.09, 0.10) & (D, D): (0.15, 0.14) & (D, D): (0.21, 0.19) & (D, D): (0.24, 0.25) \\ 

\end{tabular}





