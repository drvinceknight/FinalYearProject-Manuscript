%!TEX root = ../main.tex

\chapter{Theory}\label{cha:theory}

\section{Analytical Fingerprints}\label{sec:analytical-fingerprints}
There are several steps to constructing the Fingerprint of a strategy and basic knowledge of Markov Chains is required.
An outline of the steps is as follows:

\begin{enumerate}
    \item Build a Markov chain model of an IPD between the strategy and probe strategy.
    \item Construct the corresponding transition matrix.
    \item Find the steady state distribution.
    \item Calculate the overall expected score by taking the dot product of the steady state distribution with the payoff vector given in section \ref{sec:} to obtain the fingerprint function.
    %TODO - ref introduction
    \item This can then be plotted as a heatmap to make it easier to visualize.
\end{enumerate}

As an example, this process will now be applied to obtain a fingerprint for the strategy Win-Stay-Lose-Shift (sometimes referred to as Pavlov) when probed by Tit-For-Tat.

\textbf{Step 1} - Build the markov chain.

\textbf{Step 2} - Construct the transition matrix.

\begin{equation}\label{eq:transition_matrix}
%
T = \bordermatrix{~      & (C, C) & (C, D) & (D, C) & (D, D) \cr
                  (C, C) & 1 - y  & 0      & 0      & x      \cr
                  (C, D) & y      & 0      & 0      & 1 - x  \cr
                  (D, C) & 0      & 1 - y  & x      & 0      \cr
                  (D, D) & 0      & y      & 1 - x  & 0}
%
\end{equation}

\textbf{Step 3} - Find the steady state distribution.

\begin{equation}\label{eq:steady_state}
%
\pi =
\begin{bmatrix}
\cfrac{x (1 - x)}{2y(1-x) + x(1-x) + y(1-y)}, \\
\cfrac{y (1 - x)}{2y(1-x) + x(1-x) + y(1-y)}, \\
\cfrac{y (1 - y)}{2y(1-x) + x(1-x) + y(1-y)}, \\
\cfrac{y (1 - x)}{2y(1-x) + x(1-x) + y(1-y)}
\end{bmatrix}
\end{equation}
\textbf{Step 4} - Calculate the expected score.

\begin{equation}
F = \pi \cdot
\begin{bmatrix}
3 \\
0 \\
5 \\
1
\end{bmatrix}
=
\cfrac{3x(1-x) + y(1-x) + 5y(1-y)}{2y(1-x) + x(1-x) + y(1-y)}
\end{equation}

\textbf{Step 5} - Plot the resulting function. % TODO - put a plot here

\section{Finite State Machines}

%TODO - Start with formal definition, use diagrams as examples. Include relevant references.

Figure \ref{fig:Tit4TatFSM} and figure \ref{fig:PavlovFSM} show FSM (Finite State Machine) representations for Tit-For-Tat and Pavlov respectively.
However, it should be noted that FSM representations are not necessarily unique.
Nodes represent the previous action taken by the strategy and the opponent, ie. node $(D, C)$ implies that on the preceding turn, the strategy chose to Defect and the opponent chose to co-operate.
Arcs represent the choice made by the opponent at the current turn, and lead us to the state for the next turn.

These are not necessarily the simplest FSM representation of the strategies.
For example, Tit-For-Tat requires no knowledge of its own previous moves, but they have been included for completeness.

\begin{figure}[!hbtp]
    \begin{center}
        \includestandalone{../img/Tit4TatFSM}
        \caption{FSM for TitForTat}\label{fig:Tit4TatFSM}
        \includestandalone{../img/PavlovFSM}
        \caption{FSM for Pavlov (Win-Stay Lose-Shift)}\label{fig:PavlovFSM}
    \end{center}
\end{figure}

\begin{figure}[!hbtp]
    \begin{center}
        \includestandalone{../img/MajorityFSM}
        \caption{FSM for Majority in a game with 4 Turns}\label{fig:MajorityFSM}
    \end{center}
\end{figure}

In figure \ref{fig:MajorityFSM} we have a more complex FSM for the strategy Majority for a game with 4 turns.
Majority plays in the following way:

\begin{itemize}
  \item If the opponent has cooperated the majority of the time, Majority will cooperate
  \item If the opponent has defected the majority of the time, Majority will defect
  \item Note - the strategy shown is technically Soft Majority, if the opponents cooperations and defections are equal it will cooperate. Hard Majority would defect in this situation.
\end{itemize}

Clearly this means that the strategy Majority requires knowledge of all previous states.
It has been stated previously that this implies that Majority could not be represented as a FSM.
However in Theorem \ref{thm:fsm} it is shown that if the number of turns in a game is known, any strategy can be represented as a FSM.
This will be proved in two different ways:
\begin{itemize}
  \item Firstly, by altering the definition of an automaton
  \item
\end{itemize}
A formal defintion of a Finite State Machine is given by Definition \ref{def:fsm} but first we will outline some motivating key characteristics of a system that can be modeled with a FSM:

\begin{itemize}
 \item The system must be describable by a finite set of states.
 \item The system must have a finite set of inputs that can trigger transitions between states.
 \item The behavior of the system at a given point in time depends upon the current state and the input that occurs at that time.
 \item For each state the system may be in, behavior is defined for each possible input.
 \item The system has a particular initial state.
\end{itemize}

\begin{definition}\label{def:fsm}
A \textbf{Deterministic Finite State Machine} $M$ is a tuple $(S, \sigma, \delta, s_0, F)$ where
\begin{itemize}
 \item $\sigma$ is the set of symbols representing the input of $M$.
 \item $S$ is the set of states of $M$.
 \item $s_0 \in S$ is the starting state.
 \item $F \subseteq S$ is the set of final states of $M$.
 \item $\delta: S \times \sigma \rightarrow S$ is the transition function.
\end{itemize}
\end{definition}
%TODO - Add a little paragraph here that shows how this definition matches up with the previous examples.




\begin{theorem}\label{thm:fsm}
Given a deterministic strategy $\alpha$ and 2 histories $h_1, h_2$, then for all games of length $n \in \mathbb{N}$ there exists a FSM such that $\alpha(h_1, h_2)$ can be obtained from the FSM.
\end{theorem}

\begin{proof}\label{prf:fsm}
Let $\sigma = \{C, D\}$ and
\[
S = \bigcup_{i=0}^{n+1} \{C, D\}^i \times \{C, D\}^i
\delta((h_1, h_2), a) =()
\]

\end{proof}



\lipsum
